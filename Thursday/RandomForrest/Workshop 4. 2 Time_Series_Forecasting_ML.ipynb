{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop 4.2 Time_Series_Forecasting_ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training any supervised learning model, it is important to split the data into training and test data. The training data is used to fit the model. The algorithm uses the training data to learn the relationship between the features and the target. The test data is used to evaluate the performance of the model.\n",
    "\n",
    "\n",
    "To fit and train aa model, we’ll be following The Machine Learning Workflow:\n",
    "\n",
    "- Feature engineering\n",
    "- Split the data\n",
    "- Train the model\n",
    "- Hyperparameter tuning\n",
    "- Assess model performance\n",
    "\n",
    "\n",
    "\n",
    "To know how a random forest algorithm works we need to know Decision Trees which is again a Supervised Machine Learning algorithm used for classification as well as regression problems. Decision Trees are used for both regression and classification problems. \n",
    "\n",
    "\n",
    "Ensemble learning is the process of using multiple models, trained over the same data, averaging the results of each model ultimately finding a more powerful predictive/classification result.\n",
    "\n",
    "We will use the sklearn module for training our random forest regression model, specifically the RandomForestRegressor function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UJ0Cz6QGg05b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "\n",
    "df=pd.DataFrame()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UV7Nv-cdofN_"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Alcohol_Sales.csv',index_col='DATE',parse_dates=True)\n",
    "df.index.freq = 'MS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "Q7mpZYaUolP5",
    "outputId": "4febfc3f-228f-473c-8aee-0901aa566d90"
   },
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Visualise data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"Alcohol_Sales.csv\")\n",
    "df.columns = [\"date\", \"sales\"]\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df = df.set_index(\"date\")\n",
    "\n",
    "df_train = df.iloc[:-48]\n",
    "df_test = df.iloc[-48:]\n",
    "\n",
    "plt.figure(figsize = (18,7))\n",
    "plt.plot(df, label=\"Training data\")\n",
    "plt.plot(df_test, label = \"Test data\")\n",
    "plt.grid(alpha=0.5)\n",
    "plt.margins(x=0)\n",
    "plt.title(\"Alcohol Sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "DxtdaUjnhTtM",
    "outputId": "bcc8f5a4-8c60-475f-cb3c-1d153a0484c9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.columns = ['Sales']\n",
    "plt.figure()\n",
    "df.plot(figsize=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "id": "kKO7D16Uh6IT",
    "outputId": "35a7f0cc-26c3-479f-e99a-c1d0c8b27abf"
   },
   "outputs": [],
   "source": [
    "df['Sale_LastMonth']=df['Sales'].shift(+1)\n",
    "df['Sale_2Monthsback']=df['Sales'].shift(+2)\n",
    "df['Sale_3Monthsback']=df['Sales'].shift(+3)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "id": "MzLs40rfoOmE",
    "outputId": "286c2990-5d7d-4245-d1da-a8b047807b2a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import shift method (if needed to look at data)\n",
    "from scipy.ndimage import shift\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ahAlfSPVv75K",
    "outputId": "5ea7ee90-2535-494f-df5e-2ae84d7bad2a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x1,x2,x3,y=df['Sale_LastMonth'],df['Sale_2Monthsback'],df['Sale_3Monthsback'],df['Sales']\n",
    "x1,x2,x3,y=np.array(x1),np.array(x2),np.array(x3),np.array(y)\n",
    "x1,x2,x3,y=x1.reshape(-1,1),x2.reshape(-1,1),x3.reshape(-1,1),y.reshape(-1,1)\n",
    "final_x=np.concatenate((x1,x2,x3),axis=1)\n",
    "print(x1.shape)\n",
    "final_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's understand the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_x[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(final_x[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rf0EZs7siAiU"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_model=LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sOxBkE40uRA1"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model=RandomForestRegressor(n_estimators=100,max_features=3, random_state=18)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B99Pp3kHwdYS"
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=final_x[:-30],final_x[-30:],y[:-30],y[-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[1,1]  #got it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model, fitting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first create an instance of the Random Forest model, with the default parameters. We then fit this to our training data. We pass both the features and the target variable, so the model can learn.\n",
    "\n",
    "So our models from working with the RandomForestRegressor and LinearRegression algorythms give us : m1 and m2 (models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "syZCIXs3p8sW",
    "outputId": "cbe93bdc-3798-4adf-af9c-56dac2a4ae19"
   },
   "outputs": [],
   "source": [
    "m1=model.fit(X_train,y_train.ravel())\n",
    "m2=lin_model.fit(X_train,y_train.ravel())\n",
    "\n",
    "# the simpler option m1=model.fit(X_train,y_train) didn't work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have a trained Random Forest **model**, but we need to find out whether it is making accurate predictions for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "FKtiB1vpwivF",
    "outputId": "7e7a0f72-98ae-4030-9869-d700eaf3a6e6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred=model.predict(X_test)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,8)\n",
    "\n",
    "\n",
    "plt.plot(pred,label='Random_Forest_Predictions')\n",
    "plt.plot(y_test,label='Actual Sales')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understand the output, the data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have also  trained the **Linear Regression model**, but we need to find out whether it is making accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "zwtbfMXSq9TU",
    "outputId": "200b2b09-5f3e-4c9c-e687-5ac9ac9af0c0"
   },
   "outputs": [],
   "source": [
    "linpred=lin_model.predict(X_test)\n",
    "#linpredshifted = shift(linpred, 1, cval=np.NaN)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (11,6)\n",
    "plt.plot(linpred,label='Linear_Regression_Predictions')\n",
    "plt.plot(y_test,label='Actual Sales')\n",
    "plt.legend(loc=\"upper left\")\n",
    "#plt.ylim((0,15000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both models seem ok."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Statistics and Accuracy of the model\n",
    "\n",
    "The simplest way to evaluate these models is using accuracy; we check the predictions against the actual values in the test sets and count up how many the models got right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " When viewing the performance metrics of a regression model, we can use factors such as mean squared error, root mean squared error, $R^²$, adjusted $r^²$, and others. For this article I will focus on mean squared error and root mean squared error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: mean squared error (MSE) \n",
    "    \n",
    "* Our goal is to reduce the MSE as much as possible. *  \n",
    "\n",
    "For example, if we have an actual output array of (3,5,7,9) and a predicted output of (4,5,7,7), then we could calculate the mean squared error as:\n",
    "$((3-4)^² + (5–5)^² + (7–7)^² +(9–7)^²)/4 = (1+0+0+4)/4 = 5/4 = 1.25$\n",
    "\n",
    "\n",
    "The root mean squared error (RMSE) is just simply the square root of the MSE, so the in this case the $ RMSE = 1.25^.5 = 1.12$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-K82kVphnFxT"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "rmse_rf=sqrt(mean_squared_error(pred,y_test))\n",
    "rmse_lr=sqrt(mean_squared_error(linpred,y_test))\n",
    "print('Mean Squared Error for Random Forest Model is:',rmse_rf)\n",
    "print('Mean Squared Error for Linear Regression Model is:',rmse_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TsrxmqpSwqi6",
    "outputId": "8568673b-4343-40ae-fc74-36af18d37d5e"
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy Score for Random Forest Model:\", m1.score(X_test, y_test))\n",
    "print(\"Accuracy Score for Linear Regression Model:\", m2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#residual plots to compare oredicted values with test values\n",
    "\n",
    "plt.plot(np.ravel(y_test)-pred, marker='D',c='green', alpha=0.35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWvymQjOwtpI"
   },
   "source": [
    "## More about the parameters of the Random Forrest algorythm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RandomForestRegressor documentation shows many different parameters we can select for our model. Some of the important parameters are highlighted below:\n",
    "\n",
    "- **n_estimators** — the number of decision trees you will be running in the model\n",
    "- **criterion** — this variable allows you to select the criterion (loss function) used to determine model outcomes. We can select from loss functions such as mean squared error (MSE) and mean absolute error (MAE). The default value is MSE.\n",
    "- **max_depth** — this sets the maximum possible depth of each tree\n",
    "- **max_features** — the maximum number of features the model will consider when determining a split\n",
    "- **bootstrap** — the default value for this is True, meaning the model follows bootstrapping principles (defined earlier)\n",
    "- max_samples — This parameter assumes bootstrapping is set to True, if not, this parameter doesn’t apply. In the case of True, this value sets the largest size of each sample for each tree.\n",
    "\n",
    "- **Other** important parameters are min_samples_split, min_samples_leaf, n_jobs, and others that can be read in the sklearn’s RandomForestRegressor documentation here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators = 300, max_features = 'sqrt', max_depth = 5, random_state = 18).fit(x_train, y_train)\n",
    "\n",
    "What does it mean?\n",
    "\n",
    "Looking at our base model above, we are using 300 trees; max_features per tree is equal to the squared root of the number of parameters in our training dataset. The max depth of each tree is set to 5. And lastly, the random_state was set to 18 just to keep everything standard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model=RandomForestRegressor(n_estimators=100,max_features=3, random_state=1)\n",
    "\n",
    "\n",
    "# 100 trees\n",
    "# he random_state was set to 1 just to keep everything standard.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "rmse_rf=sqrt(mean_squared_error(pred,y_test))\n",
    "rmse_lr=sqrt(mean_squared_error(lin_pred,y_test))\n",
    "print('RMSE Mean Squared Err for Random Forest Model is:',rmse_rf)\n",
    "print('RMSE Mean Squared Err for Linear Regression Model is:',rmse_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our results from this basic random forest model weren’t that great overall. The RMSE value of 1913 is pretty high given most values of our dataset are between 10000–14000. Looking ahead, we will see if tuning helps create a better performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ravel(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cons:\n",
    "    \n",
    "    One thing to consider when running random forest models on a large dataset is the potentially long training time. For example, the time required to run this first basic model was about 30 seconds, which isn’t too bad, but as I’ll demonstrate shortly, this time requirement can increase quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Step: Using GridSearchCV to optimize your Machine Learning model\n",
    "    \n",
    " Now that we did our basic random forest regression, we will look to find a better performing choice of parameters and will do this utilizing the GridSearchCV sklearn method.\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(coddnfusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define Grid \n",
    "grid1 = { \n",
    "    'n_estimators': [200,300],\n",
    "    'max_features': ['sqrt','log2'],\n",
    "    'max_depth' : [3,4,5,6,7],\n",
    "    'random_state' : [18]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I included two print statements that will display the current datetime, this way we can track the start and end-times of the function to measure the runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "## show start time\n",
    "print(datetime.datetime.now())\n",
    "## Grid Search function\n",
    "CV_rfr = GridSearchCV(estimator=RandomForestRegressor(), param_grid=grid1, cv= 5)\n",
    "CV_rfr.fit(X_train, y_train)\n",
    "## show end time\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Evaluation Metrics\n",
    "Let’s look at the confusion matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More on Data and models to predict sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decompose=seasonal_decompose(df)\n",
    "decompose.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "tesa=ExponentialSmoothing(df,trend='add',seasonal='add',seasonal_periods=12).fit().fittedvalues.rename('tripple-expo add')\n",
    "tesm=ExponentialSmoothing(df,trend='mul',seasonal='mul',seasonal_periods=12).fit().fittedvalues.rename('tripple-expo mul')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(figsize=(10,7),legend=True)\n",
    "tesa.plot(legend=True)\n",
    "tesm.plot(legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's zoom in:\n",
    "df.iloc[:24].plot(figsize=(10,7),legend=True,)\n",
    "tesa[:24].plot(legend=True)\n",
    "tesm[:24].plot(legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "print('rmse tesa:',r2_score(df,tesa))\n",
    "print('rmse tesm:',r2_score(df,tesm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For curious people:\n",
    "    \n",
    "    https://www.kaggle.com/code/jshivam101998/alcohol-sales-csv-file-forecasting-for-next-3-year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Time_Series_Forecasting_ML.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
